{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 請結合前面的知識與程式碼，比較不同的 optimizer 與 learning rate 組合對訓練的結果與影響\n",
    "### 常見的 optimizer 包含\n",
    "* SGD\n",
    "* RMSprop\n",
    "* AdaGrad\n",
    "* Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# Disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 資料前處理\n",
    "def preproc_x(x, flatten=True):\n",
    "    x = x / 255.\n",
    "    if flatten:\n",
    "        x = x.reshape((len(x), -1))\n",
    "    return x\n",
    "\n",
    "def preproc_y(y, num_classes=10):\n",
    "    if y.shape[-1] == 1:\n",
    "        y = keras.utils.to_categorical(y, num_classes)\n",
    "    return y    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "\n",
    "# Preproc the inputs\n",
    "x_train = preproc_x(x_train)\n",
    "x_test = preproc_x(x_test)\n",
    "\n",
    "# Preprc the outputs\n",
    "y_train = preproc_y(y_train)\n",
    "y_test = preproc_y(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_shape, output_units=10, num_neurons=[512, 256, 128]):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "    \n",
    "    for i, n_units in enumerate(num_neurons):\n",
    "        if i == 0:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(input_layer)\n",
    "        else:\n",
    "            x = keras.layers.Dense(units=n_units, activation=\"relu\", name=\"hidden_layer\"+str(i+1))(x)\n",
    "    \n",
    "    out = keras.layers.Dense(units=output_units, activation=\"softmax\", name=\"output\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 超參數設定\n",
    "\"\"\"\n",
    "Set your required experiment parameters\n",
    "\"\"\"\n",
    "#LEARNING_RATE = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5]\n",
    "LEARNING_RATE = [1e-4, 1e-5]\n",
    "OPTIMIZERS = ['SGD','RMSprop','Adagrad','Adam'] \n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 256\n",
    "MOMENTUM = 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment with LR = 0.000100 in SGD optimizer\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 16s 325us/step - loss: 2.2514 - acc: 0.1729 - val_loss: 2.1815 - val_acc: 0.2360\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 2.1374 - acc: 0.2542 - val_loss: 2.0977 - val_acc: 0.2690\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 2.0651 - acc: 0.2787 - val_loss: 2.0353 - val_acc: 0.2919\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 2.0082 - acc: 0.2974 - val_loss: 1.9845 - val_acc: 0.3057\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.9633 - acc: 0.3125 - val_loss: 1.9456 - val_acc: 0.3220\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.9286 - acc: 0.3239 - val_loss: 1.9156 - val_acc: 0.3344\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.9000 - acc: 0.3370 - val_loss: 1.8886 - val_acc: 0.3394\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.8760 - acc: 0.3467 - val_loss: 1.8683 - val_acc: 0.3504\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.8556 - acc: 0.3543 - val_loss: 1.8495 - val_acc: 0.3508\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.8384 - acc: 0.3604 - val_loss: 1.8340 - val_acc: 0.3580\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.8233 - acc: 0.3648 - val_loss: 1.8207 - val_acc: 0.3634\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.8101 - acc: 0.3687 - val_loss: 1.8071 - val_acc: 0.3691\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.7979 - acc: 0.3730 - val_loss: 1.7946 - val_acc: 0.3724\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.7865 - acc: 0.3775 - val_loss: 1.7848 - val_acc: 0.3758\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.7761 - acc: 0.3804 - val_loss: 1.7751 - val_acc: 0.3823\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 7s 144us/step - loss: 1.7663 - acc: 0.3844 - val_loss: 1.7651 - val_acc: 0.3812\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.7562 - acc: 0.3882 - val_loss: 1.7563 - val_acc: 0.3859\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.7479 - acc: 0.3920 - val_loss: 1.7476 - val_acc: 0.3915\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.7395 - acc: 0.3943 - val_loss: 1.7414 - val_acc: 0.3904\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.7306 - acc: 0.3973 - val_loss: 1.7306 - val_acc: 0.3946\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.7226 - acc: 0.4014 - val_loss: 1.7238 - val_acc: 0.4012\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 1.7149 - acc: 0.4034 - val_loss: 1.7165 - val_acc: 0.3986\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.7077 - acc: 0.4057 - val_loss: 1.7091 - val_acc: 0.4027\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.7000 - acc: 0.4084 - val_loss: 1.7014 - val_acc: 0.4068\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.6928 - acc: 0.4125 - val_loss: 1.6946 - val_acc: 0.4091\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.6856 - acc: 0.4147 - val_loss: 1.6883 - val_acc: 0.4115\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 7s 145us/step - loss: 1.6790 - acc: 0.4159 - val_loss: 1.6832 - val_acc: 0.4144\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.6727 - acc: 0.4194 - val_loss: 1.6780 - val_acc: 0.4115\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 7s 142us/step - loss: 1.6659 - acc: 0.4218 - val_loss: 1.6696 - val_acc: 0.4206\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.6596 - acc: 0.4233 - val_loss: 1.6633 - val_acc: 0.4203\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 1.6533 - acc: 0.4252 - val_loss: 1.6582 - val_acc: 0.4208\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.6474 - acc: 0.4271 - val_loss: 1.6523 - val_acc: 0.4235\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 7s 150us/step - loss: 1.6416 - acc: 0.4296 - val_loss: 1.6470 - val_acc: 0.4275\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.6352 - acc: 0.4330 - val_loss: 1.6415 - val_acc: 0.4251\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.6295 - acc: 0.4339 - val_loss: 1.6364 - val_acc: 0.4271\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.6240 - acc: 0.4357 - val_loss: 1.6315 - val_acc: 0.4305\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.6189 - acc: 0.4385 - val_loss: 1.6256 - val_acc: 0.4325\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.6128 - acc: 0.4420 - val_loss: 1.6230 - val_acc: 0.4324\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.6084 - acc: 0.4425 - val_loss: 1.6182 - val_acc: 0.4381\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.6029 - acc: 0.4447 - val_loss: 1.6124 - val_acc: 0.4399\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.5985 - acc: 0.4463 - val_loss: 1.6078 - val_acc: 0.4397\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.5933 - acc: 0.4479 - val_loss: 1.6040 - val_acc: 0.4398\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.5886 - acc: 0.4487 - val_loss: 1.6000 - val_acc: 0.4445\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.5834 - acc: 0.4507 - val_loss: 1.5950 - val_acc: 0.4479\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.5789 - acc: 0.4522 - val_loss: 1.5959 - val_acc: 0.4454\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.5748 - acc: 0.4525 - val_loss: 1.5866 - val_acc: 0.4469\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.5697 - acc: 0.4562 - val_loss: 1.5883 - val_acc: 0.4435\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.5659 - acc: 0.4562 - val_loss: 1.5885 - val_acc: 0.4425\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.5619 - acc: 0.4577 - val_loss: 1.5766 - val_acc: 0.4517\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.5570 - acc: 0.4590 - val_loss: 1.5725 - val_acc: 0.4546\n",
      "Experiment with LR = 0.000100 in RMSprop optimizer\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.9552 - acc: 0.2953 - val_loss: 1.8177 - val_acc: 0.3442\n",
      "Epoch 2/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.7845 - acc: 0.3671 - val_loss: 1.8757 - val_acc: 0.3397\n",
      "Epoch 3/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.7030 - acc: 0.3968 - val_loss: 1.6963 - val_acc: 0.3928\n",
      "Epoch 4/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.6456 - acc: 0.4174 - val_loss: 1.6360 - val_acc: 0.4238\n",
      "Epoch 5/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.6026 - acc: 0.4326 - val_loss: 1.7001 - val_acc: 0.3929\n",
      "Epoch 6/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.5718 - acc: 0.4453 - val_loss: 1.6455 - val_acc: 0.4219\n",
      "Epoch 7/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.5381 - acc: 0.4552 - val_loss: 1.5742 - val_acc: 0.4354\n",
      "Epoch 8/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.5107 - acc: 0.4669 - val_loss: 1.6055 - val_acc: 0.4363\n",
      "Epoch 9/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.4857 - acc: 0.4741 - val_loss: 1.6312 - val_acc: 0.4235\n",
      "Epoch 10/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.4598 - acc: 0.4856 - val_loss: 1.4739 - val_acc: 0.4765\n",
      "Epoch 11/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.4404 - acc: 0.4923 - val_loss: 1.5440 - val_acc: 0.4444\n",
      "Epoch 12/50\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.4192 - acc: 0.4998 - val_loss: 1.5043 - val_acc: 0.4574\n",
      "Epoch 13/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.3982 - acc: 0.5084 - val_loss: 1.5370 - val_acc: 0.4554\n",
      "Epoch 14/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.3812 - acc: 0.5135 - val_loss: 1.5086 - val_acc: 0.4542\n",
      "Epoch 15/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.3632 - acc: 0.5211 - val_loss: 1.5059 - val_acc: 0.4678\n",
      "Epoch 16/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.3439 - acc: 0.5250 - val_loss: 1.5184 - val_acc: 0.4507\n",
      "Epoch 17/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.3287 - acc: 0.5307 - val_loss: 1.4974 - val_acc: 0.4651\n",
      "Epoch 18/50\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.3128 - acc: 0.5363 - val_loss: 1.4778 - val_acc: 0.4725\n",
      "Epoch 19/50\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.3019 - acc: 0.5412 - val_loss: 1.4460 - val_acc: 0.4885\n",
      "Epoch 20/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2832 - acc: 0.5471 - val_loss: 1.6749 - val_acc: 0.4122\n",
      "Epoch 21/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.2715 - acc: 0.5516 - val_loss: 1.3996 - val_acc: 0.5025\n",
      "Epoch 22/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2553 - acc: 0.5580 - val_loss: 1.5195 - val_acc: 0.4661\n",
      "Epoch 23/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 1.2407 - acc: 0.5637 - val_loss: 1.4842 - val_acc: 0.4839\n",
      "Epoch 24/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.2276 - acc: 0.5677 - val_loss: 1.4204 - val_acc: 0.4943\n",
      "Epoch 25/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.2144 - acc: 0.5723 - val_loss: 1.5314 - val_acc: 0.4650\n",
      "Epoch 26/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.2011 - acc: 0.5790 - val_loss: 1.4047 - val_acc: 0.5034\n",
      "Epoch 27/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1872 - acc: 0.5836 - val_loss: 1.4969 - val_acc: 0.4766\n",
      "Epoch 28/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.1723 - acc: 0.5910 - val_loss: 1.4217 - val_acc: 0.4981\n",
      "Epoch 29/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1627 - acc: 0.5928 - val_loss: 1.3362 - val_acc: 0.5283\n",
      "Epoch 30/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1517 - acc: 0.5969 - val_loss: 1.4383 - val_acc: 0.4962\n",
      "Epoch 31/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.1390 - acc: 0.6025 - val_loss: 1.4523 - val_acc: 0.4957\n",
      "Epoch 32/50\n",
      "50000/50000 [==============================] - 8s 157us/step - loss: 1.1270 - acc: 0.6055 - val_loss: 1.4154 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.1133 - acc: 0.6116 - val_loss: 1.4365 - val_acc: 0.4998\n",
      "Epoch 34/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.1030 - acc: 0.6149 - val_loss: 1.4729 - val_acc: 0.4867\n",
      "Epoch 35/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.0927 - acc: 0.6179 - val_loss: 1.3284 - val_acc: 0.5329\n",
      "Epoch 36/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.0816 - acc: 0.6226 - val_loss: 1.3857 - val_acc: 0.5198\n",
      "Epoch 37/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.0700 - acc: 0.6266 - val_loss: 1.3769 - val_acc: 0.5187\n",
      "Epoch 38/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.0584 - acc: 0.6301 - val_loss: 1.3933 - val_acc: 0.5130\n",
      "Epoch 39/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.0468 - acc: 0.6347 - val_loss: 1.4091 - val_acc: 0.5077\n",
      "Epoch 40/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.0350 - acc: 0.6374 - val_loss: 1.4723 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 1.0281 - acc: 0.6417 - val_loss: 1.5196 - val_acc: 0.4860\n",
      "Epoch 42/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 1.0149 - acc: 0.6458 - val_loss: 1.3983 - val_acc: 0.5114\n",
      "Epoch 43/50\n",
      "50000/50000 [==============================] - 8s 156us/step - loss: 1.0045 - acc: 0.6509 - val_loss: 1.3326 - val_acc: 0.5324\n",
      "Epoch 44/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.9937 - acc: 0.6529 - val_loss: 1.4176 - val_acc: 0.5131\n",
      "Epoch 45/50\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 0.9829 - acc: 0.6577 - val_loss: 1.3384 - val_acc: 0.5381\n",
      "Epoch 46/50\n",
      "50000/50000 [==============================] - 8s 159us/step - loss: 0.9727 - acc: 0.6606 - val_loss: 1.3941 - val_acc: 0.5245\n",
      "Epoch 47/50\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 0.9620 - acc: 0.6660 - val_loss: 1.4453 - val_acc: 0.5044\n",
      "Epoch 48/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.9559 - acc: 0.6687 - val_loss: 1.3434 - val_acc: 0.5370\n",
      "Epoch 49/50\n",
      "50000/50000 [==============================] - 8s 154us/step - loss: 0.9431 - acc: 0.6741 - val_loss: 1.4958 - val_acc: 0.4889\n",
      "Epoch 50/50\n",
      "50000/50000 [==============================] - 8s 153us/step - loss: 0.9328 - acc: 0.6770 - val_loss: 1.3816 - val_acc: 0.5273\n",
      "Experiment with LR = 0.000100 in Adagrad optimizer\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "hidden_layer1 (Dense)        (None, 512)               1573376   \n",
      "_________________________________________________________________\n",
      "hidden_layer2 (Dense)        (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "hidden_layer3 (Dense)        (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,738,890\n",
      "Trainable params: 1,738,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "12544/50000 [======>.......................] - ETA: 6s - loss: 2.1431 - acc: 0.2368"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\"\"\"\n",
    "建立你的訓練與實驗迴圈並蒐集資料\n",
    "\"\"\"\n",
    "def runOptimizer(opt, lr, MOMENTUM):\n",
    "    if (opt=='SGD'):\n",
    "        optimizer = keras.optimizers.SGD(lr=lr, nesterov=True, momentum=MOMENTUM)\n",
    "    elif (opt=='RMSprop'):\n",
    "        optimizer = keras.optimizers.RMSprop(lr=lr, epsilon=None, decay=0.0)\n",
    "    elif (opt=='Adagrad'):\n",
    "        optimizer = keras.optimizers.Adagrad(lr=lr, epsilon=None, decay=0.0)\n",
    "    elif (opt=='Adam'):\n",
    "        optimizer = keras.optimizers.Adam(lr=lr, epsilon=None, decay=0.0)\n",
    "    return optimizer\n",
    "\n",
    "for lr in LEARNING_RATE:\n",
    "    for opt in OPTIMIZERS:\n",
    "        keras.backend.clear_session() # 把舊的 Graph 清掉\n",
    "        print(\"Experiment with LR = %.6f in %s optimizer\" % (lr, opt))\n",
    "        model = build_mlp(input_shape=x_train.shape[1:])\n",
    "        model.summary()\n",
    "        optimizer = runOptimizer(opt, lr, MOMENTUM)\n",
    "        model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)\n",
    "\n",
    "        model.fit(x_train, y_train, \n",
    "                  epochs=EPOCHS, \n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  validation_data=(x_test, y_test), \n",
    "                  shuffle=True)\n",
    "\n",
    "        # Collect results\n",
    "        train_loss = model.history.history[\"loss\"]\n",
    "        valid_loss = model.history.history[\"val_loss\"]\n",
    "        train_acc = model.history.history[\"acc\"]\n",
    "        valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "        exp_name_tag = \"exp-lr-%s-opt-%s\" % (str(lr), opt)\n",
    "        results[exp_name_tag] = {'train-loss': train_loss,\n",
    "                                 'valid-loss': valid_loss,\n",
    "                                 'train-acc': train_acc,\n",
    "                                 'valid-acc': valid_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\"\"\"\n",
    "將實驗結果繪出\n",
    "\"\"\"\n",
    "color_bar = [\"r\", \"g\", \"b\", \"y\", \"m\", \"k\"]\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-loss'])),results[cond]['train-loss'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-loss'])),results[cond]['valid-loss'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "for i, cond in enumerate(results.keys()):\n",
    "    plt.plot(range(len(results[cond]['train-acc'])),results[cond]['train-acc'], '-', label=cond, color=color_bar[i])\n",
    "    plt.plot(range(len(results[cond]['valid-acc'])),results[cond]['valid-acc'], '--', label=cond, color=color_bar[i])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
